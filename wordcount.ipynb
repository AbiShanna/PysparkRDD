{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3854e33-e084-4f72-bd64-db5d2c8e7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895e829-2027-450f-a680-af7caeb6ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary data packages\n",
    " \n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e01dca-7d76-485b-b184-04f60802f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input data i.e book\n",
    "input = sc.textFile('/FileStore/tables/LittleWomen.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c38a9-ab5c-4091-8eeb-7392fb333ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to filter named entities:\n",
    "# Tokenize each word\n",
    "# Add position of speech tag to each word\n",
    "# Classify named entities using ne_chunk\n",
    "def get_n(tmp):\n",
    "    chunked = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(tmp)))\n",
    "    return [ \" \".join(w for w, t in elt) for elt in chunked if isinstance(elt, nltk.Tree) ]\n",
    "  \n",
    "# Data filteration (Selecting only named entities)\n",
    "# Ignore stopwords\n",
    "tmp = input.map(get_n).flatMap(lambda x:x)\n",
    "named_rdd = tmp.map(lambda x: x.lower()).filter(lambda x: x.lower() not in stopwords.words('english'))\n",
    "\n",
    "# Mapper - generate (Key,1)\n",
    "wordPairs = named_rdd.map(lambda x: (x,1))\n",
    "\n",
    "# Reducer - combine to (Key, #occurences)\n",
    "# Sort in descending order of #occurences\n",
    "wordCounts = wordPairs.reduceByKey(lambda x,y: x+y).sortBy(lambda x: -x[1])\n",
    "\n",
    "wordCounts.take(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
