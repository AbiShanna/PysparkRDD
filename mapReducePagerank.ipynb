{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347ec9c-a38e-427e-90f1-f06b56475ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683161a3-572a-4743-826a-6e2e5443cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "data = sc.textFile('/FileStore/tables/plot_summaries.txt')\n",
    "metadata = sc.textFile('/FileStore/tables/movie_metadata.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4831ab-50a8-4578-9983-5f917f2c0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get movie_id, movie_name from metadata\n",
    "metadata = metadata.map(lambda x: x.split('\\t')).map(lambda x: (x[0], x[2]))\n",
    " \n",
    "#Find total #movies\n",
    "tot_docs = data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbac83-ae06-4a57-a10d-9f5b720cebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_no_stop_words(txt):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [x.lower() for x in nltk.word_tokenize(txt) if x.lower() not in stop_words and len(x) > 2]\n",
    " \n",
    "def word_docid_1(docid, words):\n",
    "    tmp = [((x,docid),1) for x in words]\n",
    "    return tmp\n",
    " \n",
    "def cal_ifidf(lst):\n",
    "    return (lst[0]/lst[1])*math.log(tot_docs/lst[2])\n",
    "  \n",
    "def cal_idf(lst):\n",
    "    return math.log(tot_docs/lst[2])\n",
    " \n",
    "def cosine_similarity(query, data):\n",
    "    numerator = { k: [0]*len(query) for k in all_movies}\n",
    "    denom =  { k: [0]*len(query) for k in all_movies}\n",
    "    init_d = [np.square(x) for x in query.values()]\n",
    " \n",
    "    for i, wrd in enumerate(query.keys()):\n",
    "        tmp=query[wrd]\n",
    "        for doc_id,v in data[wrd]:\n",
    "            numerator[doc_id][i]= v*tmp\n",
    "            denom[doc_id][i] = np.square(v)\n",
    "    \n",
    "    for doc, lst in denom.items():\n",
    "        lst.extend(init_d)\n",
    "        denom[doc] = np.sqrt(sum(lst))\n",
    "    numerator = {k: sum(v) for k,v in numerator.items()}\n",
    "    res = {}\n",
    "    for k,v in numerator.items():\n",
    "        res[k] = v/denom[k]\n",
    " \n",
    "    return sorted(res.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fb3d2c-27cb-416c-b0a1-738d5b7ffd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING WORD COUNT\n",
    " \n",
    "# (doc_id,[words...])\n",
    "data_woth_no_stop_words = data.map(lambda x: x.split('\\t')).map(lambda x: (x[0],tokens_no_stop_words(x[1])))\n",
    "# ((word, doc_id), 1)\n",
    "map1 = data_woth_no_stop_words.flatMap(lambda x: (((i,x[0]),1) for i in x[1]))\n",
    "# (doc_id, wrds_per_doc)\n",
    "words_per_doc = data_woth_no_stop_words.map(lambda x: (x[0] ,len(x[1])))\n",
    "all_movies = words_per_doc.map(lambda x: x[0]).collect()\n",
    "# ((word, doc_id), wrd_count)\n",
    "reduce1 = map1.reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aaad78-33ec-4609-bb38-dd535b42cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE WORDCOUNT PER DOCUMENT\n",
    " \n",
    "# ((word, doc_id), wrd_count) to (doc_id, (word, wrd_count))\n",
    "map2 = reduce1.map(lambda x: (x[0][1],(x[0][0],x[1])))\n",
    "# (doc_id, (word, wrd_count)) to (doc_id, [(word, wrd_count)], wrds_per_doc)\n",
    "map2 = map2.groupByKey().mapValues(list)\n",
    "reduce2 = map2.join(words_per_doc)\n",
    "#(doc_id, [(word, wrd_count)], wrds_per_doc) to ((word, doc_id), (wrd_count, wrds_per_doc))\n",
    "map3 = reduce2.flatMap(lambda x: (((y[0], x[0]),(y[1], x[1][1])) for y in x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8023b-34df-4e69-b4cc-94a641f2cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE DOC COUNT PER WORD\n",
    " \n",
    "#((word, doc_id), (wrd_count, wrds_per_doc)) to (word, [doc_id, wrd_count, wrds_per_doc])\n",
    "map3 = map3.map(lambda x: (x[0][0], [x[0][1], x[1][0], x[1][1]]))\n",
    "# (word, [doc_id, wrd_count, wrds_per_doc]) to (word, [[doc1, wrd_count1, wrds_per_doc1]])\n",
    "map3 = map3.groupByKey().mapValues(list)\n",
    "# (word, [[doc1, wrd_count1, wrds_per_doc1]]) to ((word, doc1), [wrd_count1, wrds_per_doc1, docs_per_word])\n",
    "map3 =map3.flatMap(lambda x: (((x[0], entry[0]), [entry[1], entry[2], len(x[1])]) for entry in x[1] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978e588-866c-403e-9058-74d964356b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE IDF\n",
    "# ((word, doc1), [wrd_count1, wrds_per_doc1, docs_per_word]) to (word, tf)\n",
    "#tf = map3.map(lambda x: (x[0], cal_tf(x[1])))\n",
    "idf = map3.map(lambda x: (x[0][0], cal_idf(x[1])))\n",
    "idf = idf.distinct()\n",
    " \n",
    "# CALCULATE TF-IDF\n",
    "# ((word, doc1), [wrd_count1, wrds_per_doc1, docs_per_word]) to ((word,doc_id), tfidf)\n",
    "tfidf = map3.map(lambda x: (x[0], cal_ifidf(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d1042-9812-4653-81e4-0b00f967ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                    SINGLE WORD SEARCH \n",
    " \n",
    "#Enter the word to search below and execute the cell.\n",
    "search_word = 'katniss'\n",
    " \n",
    "###############################################################\n",
    " \n",
    "res = tfidf.filter(lambda x: x[0][0] == search_word.lower()).sortBy(lambda x: -x[1]).map(lambda x: (x[0][1], x[1]))\n",
    "res = res.join(metadata).map(lambda x: (x[1][1]))\n",
    "res.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a038f95-0efd-4dcf-a119-0d609e8dc074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
